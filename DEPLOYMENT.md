# ğŸš€ Barnes & Noble Scraper - Deployment Instructions

## ğŸ“‹ Setup Cloud Database (Supabase PostgreSQL)

### 1. Create Free Supabase Account
1. Go to **https://supabase.com**
2. Sign up with GitHub/Google (free tier: **2GB**, perfect for this project!)
3. Create new project: "bn-scraper"
4. Set a strong database password (save it!)
5. Wait 2-3 minutes for database setup

### 2. Get Database URL
1. In Supabase dashboard â†’ **Settings** â†’ **Database**
2. Scroll down to **Connection string** â†’ **URI**
3. Copy connection string like:
   ```
   postgresql://postgres:[YOUR-PASSWORD]@db.xxx.supabase.co:5432/postgres
   ```
4. Replace `[YOUR-PASSWORD]` with your actual database password

### 3. Environment Variables
Set these in your deployment platform:

```bash
DATABASE_URL=postgresql://postgres:your-password@db.xxx.supabase.co:5432/postgres
```

## ğŸŒ Deploy Options

### Option 1: Netlify (Recommended)
1. Connect GitHub repository
2. Add environment variable `DATABASE_URL`
3. Deploy as dynamic site
4. Build command: `bun run build`
5. Publish directory: `.next`

### Option 2: Vercel
1. Connect GitHub repository
2. Add environment variable `DATABASE_URL`
3. Auto-deploy

### Option 3: Railway/Render
1. Connect GitHub repository
2. Add environment variable `DATABASE_URL`
3. Auto-deploy

## âœ… Features Ready
- âœ… Multi-threading scraping (20+ threads)
- âœ… Proxy rotation & retry logic
- âœ… Real-time progress tracking
- âœ… Categories â†’ Bestsellers â†’ Product Links â†’ Products
- âœ… Export CSV/JSON
- âœ… Product Links management by category
- âœ… PostgreSQL cloud database
- âœ… Production-ready deployment

## ğŸ¯ Usage After Deploy
1. Open deployed URL
2. Test API Health (green button)
3. Crawl Categories â†’ Batch Bestsellers â†’ Batch Links
4. View results in Product Links & Products tabs
5. Export data when needed

**Expected Performance**: 5,000+ product links in ~10 minutes with batch operations!
